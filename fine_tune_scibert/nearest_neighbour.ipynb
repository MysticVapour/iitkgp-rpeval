{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@6.3.0/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min'}, 'shim': {}});\n      require([\"tabulator\"], function(Tabulator) {\n        window.Tabulator = Tabulator\n        on_load()\n      })\n      require([\"moment\"], function(moment) {\n        window.moment = moment\n        on_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 2;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.Tabulator !== undefined) && (!(window.Tabulator instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/js/tabulator.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    if (((window.moment !== undefined) && (!(window.moment instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.2.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [\"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/css/tabulator_simple.min.css?v=1.5.5\"];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='108567a4-070f-46c6-8623-64d54c519631'>\n",
       "  <div id=\"dbe3b89a-322f-4f82-9cee-89e92285a6f3\" data-root-id=\"108567a4-070f-46c6-8623-64d54c519631\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"63c0ca93-f1f1-4305-9b34-f454341ab557\":{\"version\":\"3.6.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"108567a4-070f-46c6-8623-64d54c519631\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"d46d827d-c6fe-4d4b-91a2-ed82e0a91275\",\"attributes\":{\"plot_id\":\"108567a4-070f-46c6-8623-64d54c519631\",\"comm_id\":\"8a6db3f9b1184a3aae0f0a2e6bc28803\",\"client_comm_id\":\"c33b67f79fb34dedb16e4f7c30c42bee\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"63c0ca93-f1f1-4305-9b34-f454341ab557\",\"roots\":{\"108567a4-070f-46c6-8623-64d54c519631\":\"dbe3b89a-322f-4f82-9cee-89e92285a6f3\"},\"root_ids\":[\"108567a4-070f-46c6-8623-64d54c519631\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root.Tabulator !== undefined) && ( root.Tabulator !== undefined))\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "108567a4-070f-46c6-8623-64d54c519631"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1\n",
    "\n",
    "# If not installed, you may need:\n",
    "# !pip install pathway transformers torch scikit-learn\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "import torch\n",
    "import pathway as pw\n",
    "\n",
    "# Import VectorStoreServer + VectorStoreClient from Pathway\n",
    "from pathway.xpacks.llm.vector_store import VectorStoreServer, VectorStoreClient\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "DB_PATH = \"db/research_papers.db\"  # Adjust if needed\n",
    "\n",
    "# Conferences of interest\n",
    "TARGET_CONFERENCES = [\"CVPR\", \"NeurIPS\", \"EMNLP\", \"TMLR\", \"KDD\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 263 references as a DataFrame.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conference</th>\n",
       "      <th>sections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3808_The_Distortion_of_Binomia</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>{\"output\": \"The Distortion of Binomial Voting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461_LithoBench_Benchmarking_AI</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>{\"output\": \"LithoBench: Benchmarking AI Comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9310_Multi_task_learning_with_</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>{\"output\": \"Multi-Task Learning with Summary S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>557_EmbodiedGPT_Vision_Languag</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>{\"output\": \"EmbodiedGPT: Vision-Language Pre-T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10107_Finite_Population_Regres</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>{\"output\": \"Finite Population Regression Adjus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id conference  \\\n",
       "0  3808_The_Distortion_of_Binomia    NeurIPS   \n",
       "1  461_LithoBench_Benchmarking_AI    NeurIPS   \n",
       "2  9310_Multi_task_learning_with_    NeurIPS   \n",
       "3  557_EmbodiedGPT_Vision_Languag    NeurIPS   \n",
       "4  10107_Finite_Population_Regres    NeurIPS   \n",
       "\n",
       "                                            sections  \n",
       "0  {\"output\": \"The Distortion of Binomial Voting ...  \n",
       "1  {\"output\": \"LithoBench: Benchmarking AI Comput...  \n",
       "2  {\"output\": \"Multi-Task Learning with Summary S...  \n",
       "3  {\"output\": \"EmbodiedGPT: Vision-Language Pre-T...  \n",
       "4  {\"output\": \"Finite Population Regression Adjus...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def scibert_embedder(doc_text: str) -> list[float]:\n",
    "    \"\"\"\n",
    "    Pathway-compatible embedder: takes a string and returns a list of floats.\n",
    "    We'll do mean pooling over the last_hidden_state.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(doc_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Mean pooling across the sequence dimension\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().tolist()\n",
    "    return embedding\n",
    "\n",
    "def fetch_reference_papers_df():\n",
    "    \"\"\"\n",
    "    Fetch from the same labelled_data table:\n",
    "      1) publishable = 1\n",
    "      2) conference in (\"NeurIPS\",\"KDD\",\"TMLR\",\"EMNLP\",\"CVPR\")\n",
    "    Return as a Pandas DataFrame with columns: [id, conference, sections].\n",
    "    \"\"\"\n",
    "    conf_list = [\"NeurIPS\", \"KDD\", \"TMLR\", \"EMNLP\", \"CVPR\"]\n",
    "    placeholders = \", \".join([\"?\"] * len(conf_list))\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT id, conference, sections\n",
    "        FROM labelled_data\n",
    "        WHERE publishable = 1\n",
    "          AND conference IN ({placeholders})\n",
    "    \"\"\"\n",
    "\n",
    "    conn = sqlite3.connect(\"../db/research_papers.db\")  # Adjust if needed\n",
    "    df_ref = pd.read_sql_query(query, conn, params=conf_list)\n",
    "    conn.close()\n",
    "    return df_ref\n",
    "\n",
    "df_references = fetch_reference_papers_df()\n",
    "print(f\"Fetched {len(df_references)} references as a DataFrame.\")\n",
    "df_references.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/advay/Projects/iitkgp-rpeval/.venv/lib/python3.11/site-packages/beartype/_util/hint/pep/utilpeptest.py:311: BeartypeDecorHintPep585DeprecationWarning: PEP 484 type hint typing.Sequence[str] deprecated by PEP 585. This hint is scheduled for removal in the first Python version released after October 5th, 2025. To resolve this, import this hint from \"beartype.typing\" rather than \"typing\". For further commentary and alternatives, see also:\n",
      "    https://beartype.readthedocs.io/en/latest/api_roar/#pep-585-deprecations\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStoreServer is running at http://0.0.0.0:8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Running on http://0.0.0.0:8000 ========\n",
      "(Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 (Updated)\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import pathway as pw\n",
    "from pathway.xpacks.llm.vector_store import VectorStoreServer\n",
    "\n",
    "def create_reference_pathway_table_from_df(df_ref: pd.DataFrame) -> pw.Table:\n",
    "    \"\"\"\n",
    "    Transform our reference DataFrame into a Pathway table \n",
    "    with columns named [data, _metadata] (required by VectorStoreServer).\n",
    "    Each row's `data` is the \"output\" field from your JSON,\n",
    "    `_metadata` stores {paper_id, conference_label}.\n",
    "    \"\"\"\n",
    "    rows_list = []\n",
    "\n",
    "    for _, row in df_ref.iterrows():\n",
    "        paper_id = row[\"id\"]\n",
    "        conf_label = row[\"conference\"]\n",
    "        sections_json = row[\"sections\"]\n",
    "\n",
    "        try:\n",
    "            # Parse JSON\n",
    "            sections_dict = json.loads(sections_json) if sections_json else {}\n",
    "            # Extract the \"output\" field\n",
    "            text_str = sections_dict.get(\"output\", \"\")\n",
    "            \n",
    "            # Build metadata\n",
    "            metadata_dict = {\n",
    "                \"paper_id\": paper_id,\n",
    "                \"conference_label\": conf_label\n",
    "            }\n",
    "            \n",
    "            # The server expects columns named 'data' and '_metadata'\n",
    "            rows_list.append((text_str, metadata_dict))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping paper {paper_id} due to error: {e}\")\n",
    "\n",
    "    # Create a Pandas DataFrame with columns [\"data\", \"_metadata\"]\n",
    "    df_pathway = pd.DataFrame(rows_list, columns=[\"data\", \"_metadata\"])\n",
    "    \n",
    "    # Convert to a Pathway table\n",
    "    table = pw.debug.table_from_pandas(df_pathway)\n",
    "    return table\n",
    "\n",
    "# Build the Pathway table\n",
    "reference_table = create_reference_pathway_table_from_df(df_references)\n",
    "\n",
    "def no_op_parser(contents):\n",
    "    \"\"\"\n",
    "    A custom parser that returns a list of (text, metadata) \n",
    "    but does no actual parsing, because we already have text.\n",
    "    \"\"\"\n",
    "    if isinstance(contents, str):\n",
    "        # Already a string, just wrap in a list[tuple[str, dict]]\n",
    "        return [(contents, {})]\n",
    "    else:\n",
    "        # If it arrives in bytes, decode as UTF-8\n",
    "        return [(contents.decode(\"utf-8\", errors=\"replace\"), {})]\n",
    "\n",
    "\n",
    "# Now create the VectorStoreServer using the correct columns\n",
    "server = VectorStoreServer(\n",
    "    reference_table,        # pass as a positional argument\n",
    "    embedder=scibert_embedder,\n",
    "    parser=no_op_parser,            # We already have 'data' in the doc rows\n",
    "    splitter=None,\n",
    "    doc_post_processors=None\n",
    ")\n",
    "\n",
    "server.run_server(host=\"0.0.0.0\", port=8000, threaded=True, with_cache=True)\n",
    "print(\"VectorStoreServer is running at http://0.0.0.0:8000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:pathway_engine.connectors:Parse error: cannot create a field \"query\" with type str from value Does Graph Distillation See Like Vision Dataset\n",
      "Counterpart?\n",
      "Beining Yang1,2∗ ∗, Kai Wang 3∗, Qingyun Sun 1,2† †, Cheng Ji 1,2, Xingcheng Fu 1,2,\n",
      "Hao Tang4, Yang You3, Jianxin Li1,2‡ ‡\n",
      "1School of Computer Science and Engineering, Beihang University\n",
      "2Advanced Innovation Center for Big Data and Brain Computing, Beihang University\n",
      "3National University of Singapore 4Carnegie Mellon University\n",
      "Abstract\n",
      "Training on large-scale graphs has achieved remarkable results in graph representa-\n",
      "tion learnin...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping paper 1279_Does_Graph_Distillation_S due to error: HTTPConnectionPool(host='0.0.0.0', port=8000): Read timed out. (read timeout=30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:pathway_engine.connectors:Parse error: cannot create a field \"query\" with type str from value Low-Light Image Enhancement via Structure Modeling and Guidance\n",
      "Xiaogang Xu1 Ruixing Wang2 Jiangbo Lu3∗\n",
      "1 Zhejiang Lab 2 Honor Device Co., Ltd. 3 SmartMore Corporation\n",
      "xgxu@zhejianglab.com, ruixingw@hustunique.com, jiangbo@smartmore.com\n",
      "Abstract\n",
      "This paper proposes a new framework for low-light im-\n",
      "age enhancement by simultaneously conducting the appear-\n",
      "ance as well as structure modeling. It employs the struc-\n",
      "tural feature to guide the appearance enhancement, lead-\n",
      "ing to sharp and realisti...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping paper Xu_Low-Light_Image_Enhancement_via_Structure_Modeling_and_Guidance_CVPR_2023_paper due to error: HTTPConnectionPool(host='0.0.0.0', port=8000): Read timed out. (read timeout=30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:pathway_engine.connectors:Parse error: cannot create a field \"query\" with type str from value 1000 FPS HDR Video with a Spike-RGB Hybrid Camera\n",
      "Yakun Chang1,2 Chu Zhou3 Yuchen Hong1,2 Liwen Hu2 Chao Xu3 Tiejun Huang1,2 Boxin Shi1,2*\n",
      "1 National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University\n",
      "2 National Engineering Research Center of Visual Technology, School of Computer Science, Peking University\n",
      "3 National Key Laboratory of General AI, School of Intelligence Science and Technology, Peking University\n",
      "{yakunchang, zhou chu, huliwen, tj...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping paper Chang_1000_FPS_HDR_Video_With_a_Spike-RGB_Hybrid_Camera_CVPR_2023_paper due to error: HTTPConnectionPool(host='0.0.0.0', port=8000): Read timed out. (read timeout=30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:pathway_engine.connectors:Parse error: cannot create a field \"query\" with type str from value DPF: Learning Dense Prediction Fields with Weak Supervision\n",
      "Xiaoxue Chen1, Yuhang Zheng2, Yupeng Zheng3\n",
      "Qiang Zhou1, Hao Zhao1, Guyue Zhou1, Ya-Qin Zhang1\n",
      "1AIR, Tsinghua University 2BUAA 3CASIA\n",
      "{chenxiaoxue, zhaohao}@air.tsinghua.edu.cn, zyh 021@buaa.edu.cn\n",
      "Abstract\n",
      "Nowadays, many visual scene understanding problems\n",
      "are addressed by dense prediction networks. But pixel-wise\n",
      "dense annotations are very expensive (e.g., for scene pars-\n",
      "ing) or impossible (e.g., for intrinsic image decomposition)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping paper Chen_DPF_Learning_Dense_Prediction_Fields_With_Weak_Supervision_CVPR_2023_paper due to error: HTTPConnectionPool(host='0.0.0.0', port=8000): Read timed out. (read timeout=30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:pathway_engine.connectors:Parse error: cannot create a field \"query\" with type str from value Autoregressive Visual Tracking\n",
      "Xing Wei† Yifan Bai† Yongchao Zheng† Dahu Shi‡§ Yihong Gong†\u0000\n",
      "†Xi’an Jiaotong University ‡Zhejiang University §Hikvision Research Institute\n",
      "{weixing, ygong}@mail.xjtu.edu.cn {yfbai, zyc}@stu.xjtu.edu.cn shidahu@zju.edu.cn\n",
      "Abstract\n",
      "We presentARTrack, an autoregressive framework for\n",
      "visual object tracking. ARTrack tackles tracking as a co-\n",
      "ordinate sequence interpretation task that estimates object\n",
      "trajectories progressively, where the current estimate is in-\n",
      "duce...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping paper Wei_Autoregressive_Visual_Tracking_CVPR_2023_paper due to error: HTTPConnectionPool(host='0.0.0.0', port=8000): Read timed out. (read timeout=30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:pathway_engine.connectors:Parse error: cannot create a field \"query\" with type str from value Multiplex Heterogeneous Graph Neural Network with Behavior\n",
      "Pattern Modeling\n",
      "Chaofan Fu\n",
      "Ocean University of China\n",
      "Qingdao, China\n",
      "fuchaofan@stu.ouc.edu.cn\n",
      "Guanjie Zheng\n",
      "Shanghai Jiao Tong University\n",
      "Shanghai, China\n",
      "gjzheng@sjtu.edu.cn\n",
      "Chao Huang\n",
      "The University of Hong Kong\n",
      "Hong Kong, China\n",
      "chaohuang75@gmail.com\n",
      "Yanwei Yu∗\n",
      "Ocean University of China\n",
      "Qingdao, China\n",
      "yuyanwei@ouc.edu.cn\n",
      "Junyu Dong\n",
      "Ocean University of China\n",
      "Qingdao, China\n",
      "dongjunyu@ouc.edu.cn\n",
      "ABSTRACT\n",
      "Heterogeneous graph neural netwo...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping paper 3580305.3599441 due to error: HTTPConnectionPool(host='0.0.0.0', port=8000): Read timed out. (read timeout=30)\n",
      "Classified 257 'publishable' papers.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4\n",
    "\n",
    "def fetch_publishable_papers():\n",
    "    \"\"\"\n",
    "    Load only the 'publishable' papers (publishable=1) from labelled_data.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(\"../db/research_papers.db\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT id, file_name, sections FROM labelled_data WHERE publishable = 1\")\n",
    "    rows = cur.fetchall()\n",
    "    conn.close()\n",
    "    return rows\n",
    "\n",
    "client = VectorStoreClient(host=\"0.0.0.0\", port=8000, timeout=30)\n",
    "\n",
    "def classify_publishable_paper(paper_text: str, k=3) -> (str, str):\n",
    "    \"\"\"\n",
    "    Queries the server with the full paper text, gets top-k matches,\n",
    "    picks the best conference by majority or top distance,\n",
    "    and returns (conference_label, justification).\n",
    "    \"\"\"\n",
    "    # Query the vector store\n",
    "    results = client.query(query=paper_text, k=k)\n",
    "    # 'results' is a list of dicts with:\n",
    "    #  - 'text': the reference text\n",
    "    #  - 'metadata': the original metadata we stored\n",
    "    #  - 'score': the similarity/distance\n",
    "\n",
    "    conference_counts = {}\n",
    "    for r in results:\n",
    "        meta = r[\"metadata\"]   # {'paper_id': ..., 'conference_label': ...}\n",
    "        conf_label = meta[\"conference_label\"]\n",
    "        conference_counts[conf_label] = conference_counts.get(conf_label, 0) + 1\n",
    "\n",
    "    # Simple majority\n",
    "    best_conference = None\n",
    "    best_count = 0\n",
    "    for conf, count in conference_counts.items():\n",
    "        if count > best_count:\n",
    "            best_conference = conf\n",
    "            best_count = count\n",
    "\n",
    "    # Provide a short justification (<=100 words)\n",
    "    justification = (\n",
    "        f\"This paper shows strong similarity to {best_conference} reference documents. \"\n",
    "        f\"The methods and findings appear aligned with the focus of {best_conference}, \"\n",
    "        f\"making it a suitable conference choice.\"\n",
    "    )\n",
    "\n",
    "    # Truncate to ~100 words if necessary\n",
    "    words = justification.split()\n",
    "    if len(words) > 100:\n",
    "        justification = \" \".join(words[:100])\n",
    "    \n",
    "    return best_conference, justification\n",
    "\n",
    "def classify_all_publishable_papers():\n",
    "    results = []\n",
    "    publishable_papers = fetch_publishable_papers()\n",
    "    for (paper_id, file_name, sections_json) in publishable_papers:\n",
    "        try:\n",
    "            sections = json.loads(sections_json)\n",
    "            paper_text = \" \".join(sections.values()) if isinstance(sections, dict) else \"\"\n",
    "            if not paper_text.strip():\n",
    "                continue\n",
    "            conf_label, justification = classify_publishable_paper(paper_text, k=3)\n",
    "            results.append((paper_id, file_name, conf_label, justification))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping paper {paper_id} due to error: {e}\")\n",
    "    return results\n",
    "\n",
    "classified_publishable = classify_all_publishable_papers()\n",
    "print(f\"Classified {len(classified_publishable)} 'publishable' papers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Paper ID: 3808_The_Distortion_of_Binomia, File: 3808_The_Distortion_of_Binomia.pdf\n",
      "Recommended Conference: NeurIPS\n",
      "Justification: This paper shows strong similarity to NeurIPS reference documents. The methods and findings appear aligned with the focus of NeurIPS, making it a suitable conference choice.\n",
      "\n",
      "==================================================\n",
      "Paper ID: 461_LithoBench_Benchmarking_AI, File: 461_LithoBench_Benchmarking_AI.pdf\n",
      "Recommended Conference: CVPR\n",
      "Justification: This paper shows strong similarity to CVPR reference documents. The methods and findings appear aligned with the focus of CVPR, making it a suitable conference choice.\n",
      "\n",
      "==================================================\n",
      "Paper ID: 9310_Multi_task_learning_with_, File: 9310_Multi_task_learning_with_.pdf\n",
      "Recommended Conference: NeurIPS\n",
      "Justification: This paper shows strong similarity to NeurIPS reference documents. The methods and findings appear aligned with the focus of NeurIPS, making it a suitable conference choice.\n",
      "\n",
      "==================================================\n",
      "Paper ID: 557_EmbodiedGPT_Vision_Languag, File: 557_EmbodiedGPT_Vision_Languag.pdf\n",
      "Recommended Conference: EMNLP\n",
      "Justification: This paper shows strong similarity to EMNLP reference documents. The methods and findings appear aligned with the focus of EMNLP, making it a suitable conference choice.\n",
      "\n",
      "==================================================\n",
      "Paper ID: 10107_Finite_Population_Regres, File: 10107_Finite_Population_Regres.pdf\n",
      "Recommended Conference: NeurIPS\n",
      "Justification: This paper shows strong similarity to NeurIPS reference documents. The methods and findings appear aligned with the focus of NeurIPS, making it a suitable conference choice.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5\n",
    "\n",
    "for (paper_id, file_name, conf_label, justification) in classified_publishable[:5]:\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Paper ID: {paper_id}, File: {file_name}\")\n",
    "    print(f\"Recommended Conference: {conf_label}\")\n",
    "    print(f\"Justification: {justification}\\n\")\n",
    "\n",
    "# (Optional) Write to a new DB table\n",
    "def store_classification_results(results):\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS recommended_conferences (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            paper_id INTEGER,\n",
    "            file_name TEXT,\n",
    "            recommended_conf TEXT,\n",
    "            justification TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    for paper_id, file_name, conf_label, justification in results:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO recommended_conferences (paper_id, file_name, recommended_conf, justification)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "        \"\"\", (paper_id, file_name, conf_label, justification))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Uncomment to store the classification in DB:\n",
    "# store_classification_results(classified_publishable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Papers Evaluated: 257\n",
      "Accuracy: 93.39%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40  0  4  2  4]\n",
      " [ 0 44  1  2  0]\n",
      " [ 2  2 49  0  0]\n",
      " [ 0  0  0 48  0]\n",
      " [ 0  0  0  0 59]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     NeurIPS       0.95      0.80      0.87        50\n",
      "         KDD       0.96      0.94      0.95        47\n",
      "        TMLR       0.91      0.92      0.92        53\n",
      "       EMNLP       0.92      1.00      0.96        48\n",
      "        CVPR       0.94      1.00      0.97        59\n",
      "\n",
      "    accuracy                           0.93       257\n",
      "   macro avg       0.94      0.93      0.93       257\n",
      "weighted avg       0.93      0.93      0.93       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Evaluate classification accuracy on publishable papers\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Suppose you used the same DB_PATH as before\n",
    "DB_PATH = \"../db/research_papers.db\"\n",
    "\n",
    "# 1) Convert your classification results list into a DataFrame\n",
    "# classified_publishable is of the form: [(paper_id, file_name, conf_label, justification), ...]\n",
    "df_pred = pd.DataFrame(\n",
    "    classified_publishable, \n",
    "    columns=[\"paper_id\", \"file_name\", \"predicted_conf\", \"justification\"]\n",
    ")\n",
    "\n",
    "# 2) Fetch true conference labels for these papers\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "df_gold = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT id AS paper_id, conference AS true_conf\n",
    "    FROM labelled_data\n",
    "    WHERE publishable = 1\n",
    "      AND conference IN (\"NeurIPS\",\"KDD\",\"TMLR\",\"EMNLP\",\"CVPR\")\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "conn.close()\n",
    "\n",
    "# 3) Merge the predicted DataFrame (df_pred) with df_gold on paper_id\n",
    "df_merged = pd.merge(df_pred, df_gold, on=\"paper_id\", how=\"inner\")\n",
    "\n",
    "# 4) Compute accuracy\n",
    "df_merged[\"correct\"] = df_merged[\"predicted_conf\"] == df_merged[\"true_conf\"]\n",
    "accuracy = df_merged[\"correct\"].mean()  # True = 1.0, so mean is accuracy\n",
    "\n",
    "print(f\"Total Papers Evaluated: {len(df_merged)}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# 5) Print confusion matrix & classification report\n",
    "TARGET_CONFERENCES = [\"NeurIPS\",\"KDD\",\"TMLR\",\"EMNLP\",\"CVPR\"]\n",
    "\n",
    "y_true = df_merged[\"true_conf\"]\n",
    "y_pred = df_merged[\"predicted_conf\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=TARGET_CONFERENCES))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, labels=TARGET_CONFERENCES))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
